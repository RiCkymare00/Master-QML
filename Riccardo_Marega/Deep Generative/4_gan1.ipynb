{"cells":[{"cell_type":"markdown","metadata":{"id":"Wot0s45KOLXR"},"source":["# Preliminaries"]},{"cell_type":"markdown","metadata":{"id":"E5XdyxvrOLXU"},"source":["\n","GANs are a class of unsupervised generative models which implicitly model the data density.\n","\n","The basic setup is pictured above. There are two \"competing\" neural networks:\n","* The Generator wants to learn to generate realistic images that are indistinguishable from the real data.\n","    - *input*: Gaussian noise random sample. *output*: a (higher dimensional) datapoint\n","* The Discriminator wants to tell the real & fake images apart.\n","    - *input*: datapoint/image, *output*: probability assigned to datapoint being real. Think binary classifier.\n","* The typical analogy: the generator is like a counterfeiter trying to look like real, the discriminator is the police trying to tell counterfeits from the real work.\n","* The key novelty of GANs is to pass the error signal (gradients) from the discriminator to the generator: the generator neural network uses the information from the competing discriminator neural network to know how to produce more realistic output."]},{"cell_type":"markdown","metadata":{"id":"27lO3QSzOLXV"},"source":["Let's start with defining the generator G and discriminator D in pytorch."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ropMkTLTiWos"},"outputs":[],"source":["import sys\n","print(sys.version) # python 3.6\n","import torch\n","import torch.nn as nn\n","import torchvision.datasets\n","import torchvision.transforms as transforms\n","import torch.nn.functional as F\n","import torchvision.utils as vutils\n","print(torch.__version__) # 1.0.1\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","def show_imgs(x, new_fig=True):\n","    grid = vutils.make_grid(x.detach().cpu(), nrow=8, normalize=True, pad_value=0.3)\n","    grid = grid.transpose(0,2).transpose(0,1) # channels as last dimension\n","    if new_fig:\n","        plt.figure()\n","    plt.imshow(grid.numpy())"]},{"cell_type":"markdown","metadata":{"id":"e6i9HK4rOLXd"},"source":["## Defining the neural networks"]},{"cell_type":"markdown","metadata":{"id":"oLmX8bdKOLXe"},"source":["Let's define a small 2-layer fully connected neural network (so one hidden layer) for the discriminator `D`:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yMTVww4jOLXe"},"outputs":[],"source":["class Discriminator(torch.nn.Module):\n","    def __init__(self, inp_dim=784):\n","        super(Discriminator, self).__init__()\n","        self.fc1 = nn.Linear(inp_dim, 128)\n","        self.nonlin1 = nn.LeakyReLU(0.2)\n","        self.fc2 = nn.Linear(128, 1)\n","    def forward(self, x):\n","        x = x.view(x.size(0), -1) # flatten (bs x 1 x 28 x 28) -> (bs x 784)\n","        h = self.nonlin1(self.fc1(x))\n","        out = self.fc2(h)\n","        out = torch.sigmoid(out)\n","        return out"]},{"cell_type":"markdown","metadata":{"id":"fLDTPJbaOLXe"},"source":["And a small 2-layer neural network for the generator `G`. `G` takes a 100-dimensional noise vector and generates an output of the size matching the data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sq4EA3YbOLXe"},"outputs":[],"source":["class Generator(nn.Module):\n","    def __init__(self, z_dim=100):\n","        super(Generator, self).__init__()\n","        self.fc1 = nn.Linear(z_dim, 128)\n","        self.nonlin1 = nn.LeakyReLU(0.2)\n","        self.fc2 = nn.Linear(128, 784)\n","    def forward(self, x):\n","        h = self.nonlin1(self.fc1(x))\n","        out = self.fc2(h)\n","        out = torch.tanh(out) # range [-1, 1]\n","        # convert to image\n","        out = out.view(out.size(0), 1, 28, 28)\n","        return out\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IkuvuogaOLXf"},"outputs":[],"source":["# instantiate a Generator and Discriminator according to their class definition.\n","D = Discriminator()\n","print(D)\n","G = Generator()\n","print(G)"]},{"cell_type":"markdown","metadata":{"id":"vlrwBAnhOLXf"},"source":["Note that the dimensions of D input and G output were defined for MNIST data."]},{"cell_type":"markdown","metadata":{"id":"RVyq27kbOLXf"},"source":["## Testing the neural networks (forward pass)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XrAQC0Y-OLXf"},"outputs":[],"source":["# A small batch of 3 samples, all zeros.\n","samples = torch.randn(5, 1, 28, 28) # batch size x channels x width x height\n","# This is how to do a forward pass (calls the .forward() function under the hood)\n","D(samples)"]},{"cell_type":"markdown","metadata":{"id":"7N3PI4YoOLXg"},"source":["Things to try:\n","* What happens if you change the number of samples in a batch?\n","* What happens if you change the width/height of the input?\n","* What are the weights of the discriminator? You can get an iterator over them with `.parameters()` and `.named_parameters()`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EEoqKQymOLXg"},"outputs":[],"source":["for name, p in D.named_parameters():\n","    print(name, p.shape)"]},{"cell_type":"markdown","metadata":{"id":"K32K5iT8OLXg"},"source":["We will think of the concatentation of all these discriminator weights in one big vector as $\\theta_D$.\n","\n","Similaryly we call the concatentation of all the generator weights in one big vector as $\\theta_G$."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Fv9hMJDOLXh"},"outputs":[],"source":["for name, p in G.named_parameters():\n","    print(name, p.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kf1X1I1aOLXh"},"outputs":[],"source":["# A small batch of 2 samples, random noise.\n","z = torch.randn(2, 100)\n","# This is how to do a forward pass (calls the .forward() function under the hood)\n","x_gen = G(z)\n","x_gen.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JeW_20VhOLXh"},"outputs":[],"source":["z = torch.randn(2, 100)\n","show_imgs(G(z))"]},{"cell_type":"markdown","metadata":{"id":"FHcW0k1DOLXi"},"source":["## Loading the data and computing forward pass"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PH8zthzBhjKS"},"outputs":[],"source":["# let's download the Fashion MNIST data, if you do this locally and you downloaded before,\n","# you can change data paths to point to your existing files\n","# dataset = torchvision.datasets.MNIST(root='./MNISTdata', ...)\n","dataset = torchvision.datasets.FashionMNIST(root='./FashionMNIST/',\n","                       transform=transforms.Compose([transforms.ToTensor(),\n","                                                     transforms.Normalize((0.5,), (0.5,))]),\n","                       download=True)\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)"]},{"cell_type":"markdown","metadata":{"id":"CNjVlTt87ou1"},"source":["Dataset and DataLoader are abstractions to help us iterate over the data in random order."]},{"cell_type":"markdown","metadata":{"id":"MlhKNiTSOLXi"},"source":["Let's look at a sample:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fzyNZ9tKOLXj"},"outputs":[],"source":["ix=200\n","x, _ = dataset[ix]\n","plt.matshow(x.squeeze().numpy(), cmap=plt.cm.gray)\n","plt.colorbar()"]},{"cell_type":"markdown","metadata":{"id":"PZABymQwOLXj"},"source":["Feed the image into the discriminator; the output will be the probability the (untrained) discriminator assigns to this sample being real."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kCZPXGE4OLXk"},"outputs":[],"source":["# for one image:\n","Dscore = D(x)\n","Dscore"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Njs60Kn5OLXr"},"outputs":[],"source":["# How you can get a batch of images from the dataloader:\n","xbatch, _ = next(iter(dataloader))  # This fetches the first batch from the DataLoader\n","\n","# xbatch, _ = iter(dataloader).next() # 64 x 1 x 28 x 28: minibatch of 64 samples\n","#D(xbatch) # 64x1 tensor: 64 predictions of \"real\" probability\n","xbatch.shape\n","# D(xbatch).shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QnU2cHoDOLXr"},"outputs":[],"source":["show_imgs(xbatch)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XeKBcUPZOLX4"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"lB3cK63HOLX4"},"source":["We introduced and defined the generator G, the discriminator D, and the dataloader which will give us minibatches of real data. With the intermezzo on optimization we also understand how we optimize neural networks in pytorch.\n","\n","To recap the basic idea of the min-max / adversarial game:\n","* The Generator and Discriminator have competing objectives, they are \"adversaries\".\n","* The Discriminator wants to assign high probability to real images and low probability to generated (fake) images\n","* The Generator wants its generated images to look real, so wants to modify its outputs to get high scores from the Discriminator\n","* We will optimize both with SGD steps (as before): optimize $\\theta_D$ the weights of $D(x, \\theta_D)$, and  $\\theta_G$ the weights of $G(z, \\theta_G)$.\n","* Final goal of the whole min-max game is for the Generator to match the data distribution: $p_G(x) \\approx p_{data}(x)$.\n","\n","\n","Now what are the objective functions for each of them? As mentioned in the introduction, the objective for the discriminator is to classify the real images as real, so $D(x) = 1$, and the fake images as fake, so $D(G(z))=0$.\n","This is a typical binary classification problem which calls for the binary cross-entropy (BCE) loss, which encourages exactly this solution.\n","\n","For G we just try to minimize the same loss that D maximizes. See how G appears inside D? This shows how the output of the generator G is passed into the Discriminator to compute the loss.\n","\n","\n","This is the optimization problem:\n","\n","$$\n","\\min _{G} \\max _{D} V(D, G)=\\mathbb{E}_{\\boldsymbol{x} \\sim p_{\\text { data }}(\\boldsymbol{x})}[\\log D(\\boldsymbol{x})]+\\mathbb{E}_{\\boldsymbol{z} \\sim p_{\\boldsymbol{z}}(\\boldsymbol{z})}[\\log (1-D(G(\\boldsymbol{z})))]\n","$$\n","\n","We will do a single SGD step alternatingly to maximize D, then minimize G.\n","In fact for G we use a modified (non-saturing) loss $-\\log D(G(z))$. Different modifications of the loss and the relation to the distance between distributions $p_{data}$ and $p_{G}$ became a topic of research over the last years.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e_bgbW4mOLX4"},"outputs":[],"source":["# Remember we have defined the discriminator and generator as:\n","D = Discriminator()\n","print(D)\n","G = Generator()\n","print(G)\n","# Now let's set up the optimizers\n","optimizerD = torch.optim.SGD(D.parameters(), lr=0.01)\n","optimizerG = torch.optim.SGD(G.parameters(), lr=0.01)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UxeLpS_EOLX5"},"outputs":[],"source":["# and the BCE criterion which computes the loss above:\n","criterion = nn.BCELoss()"]},{"cell_type":"markdown","metadata":{"id":"3vfGeMcNOLX5"},"source":["Some things to think about / try out / investigate:\n","* what are the mean probabilities for real and fake? print them and see how they change when executing the cell above a couple of times. Does this correspond to your expectation?\n","* can you confirm how the use of the criterion maps to the objective stated above?\n","* when calling backward, the derivative of the loss wrt **what** gets computed?\n","* what does `.detach()` do? Are the Generator parameters' gradients computed?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vCMh9doIOLX5"},"outputs":[],"source":["# STEP 1: Discriminator optimization step\n","x_real, _ = next(iter(dataloader))  # This fetches the first batch from the DataLoader\n","lab_real = torch.ones(64, 1)\n","lab_fake = torch.zeros(64, 1)\n","# reset accumulated gradients from previous iteration\n","optimizerD.zero_grad()\n","\n","D_x = D(x_real)\n","lossD_real = criterion(D_x, lab_real)\n","\n","z = torch.randn(64, 100) # random noise, 64 samples, z_dim=100\n","x_gen = G(z).detach()\n","D_G_z = D(x_gen)\n","lossD_fake = criterion(D_G_z, lab_fake)\n","\n","lossD = lossD_real + lossD_fake\n","lossD.backward()\n","optimizerD.step()\n","\n","print(D_x.mean().item(), D_G_z.mean().item())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z5BZ8ztfOLX6"},"outputs":[],"source":["# STEP 2: Generator optimization step\n","# note how only one of the terms involves the Generator so this is the only one that matters for G.\n","# reset accumulated gradients from previous iteration\n","optimizerG.zero_grad()\n","\n","z = torch.randn(64, 100) # random noise, 64 samples, z_dim=100\n","D_G_z = D(G(z))\n","lossG = criterion(D_G_z, lab_real) # -log D(G(z))\n","\n","lossG.backward()\n","optimizerG.step()\n","\n","print(D_G_z.mean().item())"]},{"cell_type":"markdown","metadata":{"id":"Kv9dgcNXOLX6"},"source":["Again run this cell a couple of times. See how the generator increases its Discriminator score?\n","\n","Some more things to ponder:\n","* Do the Generator parameters now receive gradients? Why (compared to previous loop)?\n","* From the definition of BCE loss confirm that this comes down to $-\\log D(G(z))$"]},{"cell_type":"markdown","metadata":{"id":"lHip9p7POLX6"},"source":["### Putting it all together: the full training loop\n","\n","Modifications to the code:\n","* add device parameter to take GPU if available\n","* use [Adam optimizer](https://pytorch.org/docs/stable/optim.html#torch.optim.Adam) (an adaptive learning-rate variation of SGD with momentum)\n","* some very minimal logging"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cvpNx8t-OLX8"},"outputs":[],"source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","print('Device: ', device)\n","# Re-initialize D, G:\n","D = Discriminator().to(device)\n","G = Generator().to(device)\n","# Now let's set up the optimizers (Adam, better than SGD for this)\n","optimizerD = torch.optim.SGD(D.parameters(), lr=0.03)\n","optimizerG = torch.optim.SGD(G.parameters(), lr=0.03)\n","# optimizerD = torch.optim.Adam(D.parameters(), lr=0.0002)\n","# optimizerG = torch.optim.Adam(G.parameters(), lr=0.0002)\n","lab_real = torch.ones(64, 1, device=device)\n","lab_fake = torch.zeros(64, 1, device=device)\n","\n","\n","# for logging:\n","collect_x_gen = []\n","fixed_noise = torch.randn(64, 100, device=device)\n","fig = plt.figure() # keep updating this one\n","plt.ion()\n","\n","for epoch in range(3): # 10 epochs\n","    for i, data in enumerate(dataloader, 0):\n","        # STEP 1: Discriminator optimization step\n","        x_real, _ = next(iter(dataloader))  # This fetches the first batch from the DataLoader\n","        x_real = x_real.to(device)\n","        # reset accumulated gradients from previous iteration\n","        optimizerD.zero_grad()\n","\n","        D_x = D(x_real)\n","        lossD_real = criterion(D_x, lab_real)\n","\n","        z = torch.randn(64, 100, device=device) # random noise, 64 samples, z_dim=100\n","        x_gen = G(z).detach()\n","        D_G_z = D(x_gen)\n","        lossD_fake = criterion(D_G_z, lab_fake)\n","\n","        lossD = lossD_real + lossD_fake\n","        lossD.backward()\n","        optimizerD.step()\n","\n","        # STEP 2: Generator optimization step\n","        # reset accumulated gradients from previous iteration\n","        optimizerG.zero_grad()\n","\n","        z = torch.randn(64, 100, device=device) # random noise, 64 samples, z_dim=100\n","        x_gen = G(z)\n","        D_G_z = D(x_gen)\n","        lossG = criterion(D_G_z, lab_real) # -log D(G(z))\n","\n","        lossG.backward()\n","        optimizerG.step()\n","        if i % 100 == 0:\n","            x_gen = G(fixed_noise)\n","            show_imgs(x_gen, new_fig=False)\n","            fig.canvas.draw()\n","            print('e{}.i{}/{} last mb D(x)={:.4f} D(G(z))={:.4f}'.format(\n","                epoch, i, len(dataloader), D_x.mean().item(), D_G_z.mean().item()))\n","    # End of epoch\n","    x_gen = G(fixed_noise)\n","    collect_x_gen.append(x_gen.detach().clone())"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"S5_nCFjSOLX8"},"outputs":[],"source":["for x_gen in collect_x_gen:\n","    show_imgs(x_gen)"]},{"cell_type":"markdown","metadata":{"id":"cGUwvL0MOLX9"},"source":["# A demo of a state of the art GAN and \"painting\" with them in your browser:\n","\n","https://gandissect.csail.mit.edu\n","\n","By our colleagues at the MIT-IBM Watson AI Lab.\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":0}