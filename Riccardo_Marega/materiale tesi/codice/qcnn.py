# The following code is adapted from: https://arnaucasau.github.io/qiskit-machine-learning/tutorials/11_quantum_convolutional_neural_networks.html
# AIM: we wanna prove how introducting a quantum layer in a classical cnn can indeed imporve the feature extraction

'''
Theory:
First, we encode our pixelated image into a quantum circuit using a given feature map, such Qiskit’s ZFeatureMap or ZZFeatureMap or others available in the circuit library.
After encoding our image, we apply alternating convolutional and pooling layers, as defined in the next section. By applying these alternating layers, we reduce the dimensionality of our circuit until we are left with one qubit. We can then classify our input image by measuring the output of this one remaining qubit.
'''

import json
import matplotlib.pyplot as plt
import numpy as np
from IPython.display import clear_output
from qiskit import QuantumCircuit
from qiskit.circuit import ParameterVector
from qiskit.circuit.library import ZZFeatureMap
from qiskit.quantum_info import SparsePauliOp
from qiskit_algorithms.optimizers import COBYLA
from qiskit_algorithms.utils import algorithm_globals
from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier
from qiskit_machine_learning.neural_networks import EstimatorQNN
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
from PIL import Image
import os
import pylatexenc

# In a QCNN, one could in principle choose any parametrized circuit 
# for the convolutional and pooling layers. Here, we base our analysis 
# on the mathematical result that any 2-qubit unitary U belongs to SU(4).
#
# According to Vatan & Williams decomposition:
#   U = (A1 ⊗ A2) · N(α, β, γ) · (A3 ⊗ A4)
# where Ai ∈ SU(2) (3 parameters each) and
#       N(α, β, γ) = exp(i [α σx⊗σx + β σy⊗σy + γ σz⊗σz])
#       (α, β, γ are 3 real parameters)
# Total parameters: 4*3 + 3 = 15 (matches SU(4) dimension)
#
# N(α, β, γ) is the "non-local" part of the unitary, responsible for entanglement
# between the two qubits. The Ai gates are local rotations on each qubit.
#
# Using all 15 parameters would allow representing any 2-qubit unitary,
# but training would be inefficient. To simplify, we restrict our ansatz
# to only N(α, β, γ), i.e., 3 parameters per gate. 
# This reduces training cost and complexity but limits the accessible
# Hilbert space, potentially reducing QCNN accuracy.

dataset_training_path = 'archive/data_object_image_2/training/image_2'
dataset_testing_path = 'archive/data_object_image_2/training/image_2'

# Img dimension: 1242 × 375

def conv_circuit(params):
    target = QuantumCircuit(2)
    target.rz(-np.pi / 2, 1)
    target.cx(1, 0)
    target.rz(params[0], 0)
    target.ry(params[1], 1)
    target.cx(0, 1)
    target.ry(params[2], 1)
    target.cx(1, 0)
    target.rz(np.pi / 2, 0)
    return target

# In this circuit, the CX gate combined with the parametric rotations
# is an implementation equivalent to a subset of N(α, β, γ), where
# the parametric rotations "activate and modulate" the entanglement
# generated by the CX gate. Note that we are parametrizing local rotations
# that influence entanglement indirectly, rather than directly tuning
# the non-local unitary parameters α, β, γ.

def conv_layer(num_qubits, param_prefix):
    qc = QuantumCircuit(num_qubits, name="Convolutional Layer")
    qubits = list(range(num_qubits))
    param_index = 0
    params = ParameterVector(param_prefix, length = num_qubits*3)
    for q1, q2 in zip(qubits[0::2], qubits[1::2]):
        qc = qc.compose(conv_circuit(params[param_index : (param_index + 3)]), [q1, q2])
        qc.barrier()
        param_index += 3
    for q1, q2 in zip(qubits[1::2], qubits[2::2] + [0]):
        qc = qc.compose(conv_circuit(params[param_index : (param_index + 3)]), [q1, q2])
        qc.barrier()
        param_index += 3

    qc_inst = qc.to_instruction()

    qc = QuantumCircuit(num_qubits)
    qc.append(qc_inst, qubits)
    return qc

def pool_circuit(params):
    target = QuantumCircuit(2)
    target.rz(-np.pi / 2, 1)
    target.cx(1, 0)
    target.rz(params[0], 0)
    target.ry(params[1], 1)
    target.cx(0, 1)
    target.ry(params[2], 1)

    return target

def pool_layer(sources, sinks, param_prefix):
    num_qubits = len(sources) + len(sinks)
    qc = QuantumCircuit(num_qubits, name="Pooling Layer")
    param_index = 0
    params = ParameterVector(param_prefix, length=len(sources) * 3) 
    
    qubit_mapping = {}
    local_index = 0
    for source in sources:
        qubit_mapping[source] = local_index
        local_index += 1
    for sink in sinks:
        qubit_mapping[sink] = local_index
        local_index += 1
    
    for source, sink in zip(sources, sinks):
        local_source = qubit_mapping[source]
        local_sink = qubit_mapping[sink]
        qc = qc.compose(pool_circuit(params[param_index : (param_index + 3)]), [local_source, local_sink])
        qc.barrier()
        param_index += 3

    return qc

# Image resizing to 64 x 32 followed by PCA to 16 dimensions
# --------------------------------------------------------------------------------
resize_shape = (64,32)
num_components = 16

def load_images_as_vectors(folder, resize_shape):
    data = []
    files = sorted(os.listdir(folder))
    for f in files:
        if f.endswith(('.png', '.jpg', '.jpeg')):
            img = Image.open(os.path.join(folder, f)).convert('L')  
            img = img.resize(resize_shape)                          
            vec = np.asarray(img).flatten() / 255.0                
            data.append(vec)
    return np.array(data)

x_train = load_images_as_vectors(dataset_training_path, resize_shape)
x_test  = load_images_as_vectors(dataset_testing_path, resize_shape)

pca = PCA(n_components=num_components)
X_train_reduced = pca.fit_transform(x_train)   
X_test_reduced  = pca.transform(x_test)
# --------------------------------------------------------------------------------

feature_map = ZZFeatureMap(feature_dimension=num_components, reps = 1)
#feature_map.decompose().draw("mpl", style="clifford")
#plt.savefig('feature_map.png')
#plt.close()

ansatz = QuantumCircuit(16, name="Ansatz")

# First Convolutional Layer (16 qubit)
ansatz.compose(conv_layer(16, "c1"), list(range(16)), inplace=True)

# First Pooling Layer: 16 → 8 qubit
# I primi 8 qubit (0-7) sono le sorgenti, gli ultimi 8 (8-15) sono i sink
ansatz.compose(pool_layer([0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], "p1"), list(range(16)), inplace=True)

# Second Convolutional Layer (8 qubit, sui qubit 8-15)
ansatz.compose(conv_layer(8, "c2"), list(range(8, 16)), inplace=True)

# Second Pooling Layer: 8 → 4 qubit
# I primi 4 qubit del range (8-11) sono le sorgenti, gli ultimi 4 (12-15) sono i sink
ansatz.compose(pool_layer([8, 9, 10, 11], [12, 13, 14, 15], "p2"), list(range(8, 16)), inplace=True)

# Third Convolutional Layer (4 qubit, sui qubit 12-15)
ansatz.compose(conv_layer(4, "c3"), list(range(12, 16)), inplace=True)

# Third Pooling Layer: 4 → 2 qubit
# I primi 2 qubit del range (12-13) sono le sorgenti, gli ultimi 2 (14-15) sono i sink
ansatz.compose(pool_layer([12, 13], [14, 15], "p3"), list(range(12, 16)), inplace=True)

# Fourth Convolutional Layer (2 qubit, sui qubit 14-15)
ansatz.compose(conv_layer(2, "c4"), list(range(14, 16)), inplace=True)

# Fourth Pooling Layer: 2 → 1 qubit
# Il primo qubit (14) è la sorgente, l'ultimo (15) è il sink
ansatz.compose(pool_layer([14], [15], "p4"), list(range(14, 16)), inplace=True)

# Combining the feature map and ansatz
circuit = QuantumCircuit(16)
circuit.compose(feature_map, range(16), inplace=True)
circuit.compose(ansatz, range(16), inplace=True)

# L'observable deve misurare il qubit finale (qubit 15)
observable = SparsePauliOp.from_list([("I"*15 + "Z", 1)])

#circuit.decompose().draw("mpl", style="clifford")
#plt.savefig('full_circuit.png')
#plt.close()

qnn = EstimatorQNN( circuit = circuit.decompose(),
                    observables=observable,
                    input_params=feature_map.parameters,
                    weight_params=ansatz.parameters,
)

def callback_graph(weights, obj_func_eval):
    objective_func_vals.append(obj_func_eval)
    print(f"Iter {len(objective_func_vals)} | Objective value: {obj_func_eval}")

classifier = NeuralNetworkClassifier(
    qnn,
    optimizer=COBYLA(maxiter=200), 
    callback=callback_graph,
)
x = np.asarray(X_train_reduced)

def load_binary_labels(label_folder):
    labels = []
    files = sorted(os.listdir(label_folder))
    for f in files:
        if f.endswith('.txt'):
            with open(os.path.join(label_folder, f), 'r') as file:
                lines = file.readlines()
                # Se il file è vuoto, nessuna macchina presente
                if len(lines) == 0:
                    labels.append(0)
                else:
                    # Controlliamo se c'è almeno una riga con "Car"
                    car_present = any(line.split()[0] == "Car" for line in lines)
                    labels.append(1 if car_present else 0)
    return np.array(labels)

train_labels = load_binary_labels(
    "/Users/riccardomarega/Desktop/Master QML/Riccardo_Marega/materiale tesi/codice/archive/data_object_label_2/training/label_2"
)
y = np.asarray(train_labels)

objective_func_vals = []
plt.rcParams["figure.figsize"] = (12, 6)
classifier.fit(x, y)

# score classifier
print(f"Accuracy from the train data : {np.round(100 * classifier.score(x, y), 2)}%")